{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLojLUpcGNbk"
      },
      "source": [
        "# **차량 공유업체의 차량 파손 여부 분류하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbrllJY8JdkF"
      },
      "source": [
        "## 0.미션\n",
        "\n",
        "* 1) 미션1 : Data Preprocessing\n",
        "    - **과제 수행 목표**\n",
        "        - 본인의 구글 드라이브에 모델링 수행을 위해 적절한 폴더 및 파일로 **일관성 있게 정리**해야 합니다.\n",
        "        - 제공된 데이터 : Car_Images.zip\n",
        "            * Car_Images : 차량의 정상/파손 이미지 무작위 수집"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgdg96jE-mmd"
      },
      "source": [
        "* 2) 미션2 : CNN 모델링\n",
        "    - **과제 수행 목표**\n",
        "        - Tensorflow Keras를 이용하여 모델을 3개 이상 생성하세요.\n",
        "            - 모델 구조와 파라미터는 자유롭게 구성하세요.\n",
        "            - 단, 세부 목차에서 명시한 부분은 지켜주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRrUY4ud_rJV"
      },
      "source": [
        "* 3) 미션3 : Data Argumentation & Transfer Learning\n",
        "    - **과제 수행 목표**\n",
        "        - 성능 개선을 위해 다음의 두가지를 시도하세요.\n",
        "            * Data Augmentation을 적용하세요.(Image Generator)\n",
        "            * Transfer Learning(VGG16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MdjZtxfGNKz"
      },
      "source": [
        "## 1.환경설정 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QgFWzN9xhlr"
      },
      "source": [
        "### (1) 데이터셋 폴더 생성\n",
        "- **세부요구사항**\n",
        "    - C드라이브에 Datasets라는 폴더를 만드세요.\n",
        "        - 구글드라이브를 사용하는경우 드라이브 첫 화면에 Datasets 라는 폴더를 만드세요. ('/content/drive/MyDrive/Datasets/')\n",
        "    - 해당 폴더 안에 Car_Images.zip 파일을 넣으세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elg8NL8vwUs5"
      },
      "source": [
        "* 구글 Colab을 이용하는 경우"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWUbDvBzwiTq",
        "outputId": "63548e5e-23a6-437e-94f5-acb984d3ff9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sVNbCKnLUGc"
      },
      "source": [
        "### (2) 데이터셋 불러오기 \n",
        "- **세부요구사항**\n",
        "    - Car_Images.zip 파일을 C:/Datasets/ 경로에 압축 해제합니다.\n",
        "    - zipfile 모듈을 이용하거나 다른 방식을 사용해도 됩니다.\n",
        "        - 참고 자료 : [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n",
        "    - 폴더구조(로컬)\n",
        "        * C:/Datasets/ : 압축파일\n",
        "        * C:/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n",
        "    - 폴더구조(구글드라이브브)\n",
        "        * /content/drive/MyDrive/Datasets/ : 압축파일\n",
        "        * /content/drive/MyDrive/Datasets/Car_Images_train/ : 압축 해제한 이미지 저장소\n",
        "    - 압축을 해제하면 다음과 같은 두 하위 폴더가 생성됩니다.\n",
        "        * normal, abnormal : 각 폴더에는 이미지들이 있습니다.\n",
        "        * 이후 단계에서 해당 경로로 부터 validation, test 셋을 추출하게 됩니다.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2-8EaA9x4Xm"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os, numpy, pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMkstFLKx4Xm"
      },
      "outputs": [],
      "source": [
        "# 압축파일 경로\n",
        "# 구글 드라이브인 경우 경로에 맞게 지정하세요.\n",
        "dataset_path  = '/content/drive/MyDrive/Datasets/'\n",
        "# dataset_path = 'C:/Datasets/'\n",
        "\n",
        "file_path = dataset_path + 'Car_Images.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgT_RB14Lwza"
      },
      "outputs": [],
      "source": [
        "# 압축 해제\n",
        "# data = zipfile.ZipFile(file_path)\n",
        "# data.extractall('경로')\n",
        "!unzip /content/drive/MyDrive/Datasets/Car_Images.zip -d /content/drive/MyDrive/Datasets/car_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hgC0axQyMhI"
      },
      "source": [
        "### (3) 이미지 저장을 위한 폴더 생성\n",
        "- **세부요구사항**\n",
        "    - train, validation, test 을 위해 각각 하위 폴더 normal과 abnormal를 준비합니다.\n",
        "        - train\n",
        "            * 정상 이미지 저장소 : C:/Datasets/Car_Images_train/normal/ \n",
        "                * 구글드라이브 :   /content/drive/MyDrive/Datasets/Car_Images_train/normal/\n",
        "            * 파손 이미지 저장소 : C:/Datasets/Car_Images_train/abnormal/\n",
        "                * 구글드라이브 : /content/drive/MyDrive/Datasets/Car_Images_train/abnormal/\n",
        "        - val, test 역시 동일한 구조로 생성합니다.\n",
        "    - 직접 탐색기에서 폴더를 생성할 수도 있고, os 모듈을 이용하여 코드로 작성할 수도 있습니다.\n",
        "        - 참고 자료 : [os document](https://docs.python.org/3/library/os.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oyEoZp3tZMi"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/drive/MyDrive/Datasets/Car_Images_train\n",
        "!mkdir /content/drive/MyDrive/Datasets/Car_Images_validation\n",
        "!mkdir /content/drive/MyDrive/Datasets/Car_Images_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb30xCI-t-SQ"
      },
      "outputs": [],
      "source": [
        "! mkdir /content/drive/MyDrive/Datasets/Car_Images_train/normal; mkdir /content/drive/MyDrive/Datasets/Car_Images_train/abnormal\n",
        "! mkdir /content/drive/MyDrive/Datasets/Car_Images_validation/normal; mkdir /content/drive/MyDrive/Datasets/Car_Images_validation/abnormal\n",
        "! mkdir /content/drive/MyDrive/Datasets/Car_Images_test/normal; mkdir /content/drive/MyDrive/Datasets/Car_Images_test/abnormal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc8GnuauOzLf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 각각 경로 지정\n",
        "\n",
        "\n",
        "\n",
        "# train 폴더는 압축을 해제하면서 이미 생성 되어 있습니다.\n",
        "\n",
        "# test 폴더 만들기 os.mkdir()\n",
        "\n",
        "\n",
        "\n",
        "# validation 폴더 만들기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYZKJrP0GtPh"
      },
      "source": [
        "## 2.데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ilpDQfInAE"
      },
      "source": [
        "### (1) 데이터 분할 : Training set | Validation set | Test set 생성\n",
        "- **세부요구사항**\n",
        "    - Training set, Validation set, Test set을 만듭니다.\n",
        "        * size\n",
        "            * test : 전체에서 20%를 추출합니다.\n",
        "            * validation : test를 떼어낸 나머지에서 다시 20%를 추출합니다.\n",
        "        * 데이터는 랜덤하게 추출해야 합니다.\n",
        "            - random, shutil 모듈을 이용하여 랜덤하게 추출할 수 있습니다.\n",
        "                - [random document](https://docs.python.org/3/library/random.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "            * 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFMSDA26RS-E"
      },
      "source": [
        "#### 1) test, validation 크기를 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhQ_Gu_KNR2g"
      },
      "outputs": [],
      "source": [
        "import random, shutil, os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTEKCSAo4___"
      },
      "outputs": [],
      "source": [
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyistBfO40Uq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdU7X9e70dBu",
        "outputId": "a160dcfe-68b1-4de0-f45e-0972aad1c5e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(302, 303)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 전체 이미지 갯수를 확인합니다.\n",
        "ab_image_path = '/content/drive/MyDrive/Datasets/car_image/abnormal'\n",
        "nor_image_path = '/content/drive/MyDrive/Datasets/car_image/normal'\n",
        "len(os.listdir('/content/drive/MyDrive/Datasets/car_image/normal')) , len(os.listdir('/content/drive/MyDrive/Datasets/car_image/abnormal'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmOQXm4ien-v"
      },
      "outputs": [],
      "source": [
        "test_ab_dir = '/content/drive/MyDrive/Datasets/Car_Images_test/abnormal'\n",
        "val_ab_dir = '/content/drive/MyDrive/Datasets/Car_Images_validation/abnormal'\n",
        "train_ab_dir = '/content/drive/MyDrive/Datasets/Car_Images_train/abnormal'\n",
        "test_nor_dir = '/content/drive/MyDrive/Datasets/Car_Images_test/normal'\n",
        "val_nor_dir = '/content/drive/MyDrive/Datasets/Car_Images_validation/normal'\n",
        "train_nor_dir = '/content/drive/MyDrive/Datasets/Car_Images_train/normal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6xddnbczk65"
      },
      "outputs": [],
      "source": [
        "# normal\n",
        "\n",
        "# 원본 이미지 경로\n",
        "nor_dir = '/content/drive/MyDrive/Datasets/car_image/normal'\n",
        "\n",
        "# 분할된 이미지를 저장할 폴더 경로\n",
        "test_nor_dir = '/content/drive/MyDrive/Datasets/Car_Images_test/normal'\n",
        "val_nor_dir = '/content/drive/MyDrive/Datasets/Car_Images_validation/normal'\n",
        "train_nor_dir = '/content/drive/MyDrive/Datasets/Car_Images_train/normal'\n",
        "\n",
        "# 이미지 파일 목록 가져오기\n",
        "files = os.listdir(nor_dir)\n",
        "\n",
        "train_val_files, test_files = train_test_split(files, test_size=0.1, random_state=2023)\n",
        "train_files, val_files = train_test_split(train_val_files, test_size=0.2, random_state=2023)\n",
        "\n",
        "# test set 복사\n",
        "for file in test_files:\n",
        "    src_file = os.path.join(nor_dir, file)\n",
        "    dst_file = os.path.join(test_nor_dir, file)\n",
        "    shutil.copy(src_file, dst_file)\n",
        "\n",
        "# validation set 복사\n",
        "for file in val_files:\n",
        "    src_file = os.path.join(nor_dir, file)\n",
        "    dst_file = os.path.join(val_nor_dir, file)\n",
        "    shutil.copy(src_file, dst_file)\n",
        "\n",
        "# train set 복사\n",
        "for file in train_files:\n",
        "    src_file = os.path.join(nor_dir, file)\n",
        "    dst_file = os.path.join(train_nor_dir, file)\n",
        "    shutil.copy(src_file, dst_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSixw9Aj8mrK"
      },
      "outputs": [],
      "source": [
        "# abnormal\n",
        "\n",
        "# 원본 이미지 경로\n",
        "ab_dir = '/content/drive/MyDrive/Datasets/car_image/abnormal'\n",
        "\n",
        "# 분할된 이미지를 저장할 폴더 경로\n",
        "test_ab_dir = '/content/drive/MyDrive/Datasets/Car_Images_test/abnormal'\n",
        "val_ab_dir = '/content/drive/MyDrive/Datasets/Car_Images_validation/abnormal'\n",
        "train_ab_dir = '/content/drive/MyDrive/Datasets/Car_Images_train/abnormal'\n",
        "\n",
        "# 이미지 파일 목록 가져오기\n",
        "files = os.listdir(ab_dir)\n",
        "\n",
        "train_val_files, test_files = train_test_split(files, test_size=0.1, random_state=2023)\n",
        "train_files, val_files = train_test_split(train_val_files, test_size=0.2, random_state=2023)\n",
        "\n",
        "# test set 복사\n",
        "for file in test_files:\n",
        "    src_file = os.path.join(ab_dir, file)\n",
        "    dst_file = os.path.join(test_ab_dir, file)\n",
        "    shutil.copy(src_file, dst_file)\n",
        "\n",
        "# validation set 복사\n",
        "for file in val_files:\n",
        "    src_file = os.path.join(ab_dir, file)\n",
        "    dst_file = os.path.join(val_ab_dir, file)\n",
        "    shutil.copy(src_file, dst_file)\n",
        "\n",
        "# train set 복사\n",
        "for file in train_files:\n",
        "    src_file = os.path.join(ab_dir, file)\n",
        "    dst_file = os.path.join(train_ab_dir, file)\n",
        "    shutil.copy(src_file, dst_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aJ4WQ388on9",
        "outputId": "a50af819-d704-4bb0-ae19-71bcf5e7e763"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31, 216, 55)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_test/normal')), len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/normal')), len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_validation/normal'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tSL3xgL9lCe",
        "outputId": "b06e7b59-884f-42ea-ef12-7c790d33e793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31, 217, 55)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_test/abnormal')), len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_train/abnormal')), len(os.listdir('/content/drive/MyDrive/Datasets/Car_Images_validation/abnormal'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwYk2Do7eIQU",
        "outputId": "30205840-a2c3-4779-cb65-f1321fc31a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: (31, 31)\n",
            "val: (55, 55)\n",
            "train: (217, 216)\n"
          ]
        }
      ],
      "source": [
        "# 추출 후 데이터 크기\n",
        "print(f'test: {len(os.listdir(test_ab_dir)), len(os.listdir(test_nor_dir))}')\n",
        "print(f'val: {len(os.listdir(val_ab_dir)), len(os.listdir(val_nor_dir))}')\n",
        "print(f'train: {len(os.listdir(train_ab_dir)), len(os.listdir(train_nor_dir))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa2mxylBDVM5"
      },
      "outputs": [],
      "source": [
        "# # test 사이즈 : 전체 이미지의 20%\n",
        "# te_data_num = [round(len(os.listdir(nor_image_path))*0.1), round(len(os.listdir(ab_image_path))*0.1)]\n",
        "# print(te_data_num)\n",
        "\n",
        "# # validation 사이즈 : test를 제외한 나머지 중에서 20%\n",
        "# val_data_num = [ round((len(os.listdir(nor_image_path))-te_data_num[0])*0.2) , round((len(os.listdir(nor_image_path))-te_data_num[1])*0.2) ]\n",
        "# print(val_data_num)\n",
        "\n",
        "# # train 사이즈\n",
        "# train_data_num = [len(os.listdir(nor_image_path)) - te_data_num[0] - val_data_num[0],\n",
        "#                   len(os.listdir(ab_image_path))- te_data_num[1] - val_data_num[1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmRhrViWRXgL"
      },
      "source": [
        "#### 2) test 셋 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSwovHr2Fon1"
      },
      "outputs": [],
      "source": [
        "random.seed(2023)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AImO1ujiI2IY"
      },
      "outputs": [],
      "source": [
        "# 추출 후 이미지 갯수 확인\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V4mh3hxRpR2"
      },
      "source": [
        "#### 3) validation 셋 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXYmEdCjAEDu"
      },
      "outputs": [],
      "source": [
        "random.seed(2023)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIT85iSdM4U-"
      },
      "outputs": [],
      "source": [
        "# 추출 후 이미지 갯수 확인\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haSO004sgyyu"
      },
      "source": [
        "### (2) 데이터 복사 및 이동\n",
        "- **세부요구사항**\n",
        "    - 분할된 데이터를 복사 이동합니다.\n",
        "        - 새로운 폴더에 저장하는 데이터로 \"3.모델링I\"에서 사용합니다.\n",
        "        - 기존 폴더는 \"4.모델링II > (1) Data Augmentation\"에서 사용합니다.\n",
        "    - Training set | Validation set | Test set의 데이터를 **새로운 폴더**에 복사하세요.\n",
        "        - 새로운 폴더 명\n",
        "            * copy_images/trainset\n",
        "            * copy_images/validset\n",
        "            * copy_images/testset\n",
        "        - 새로운 폴더에는 normal, abnormal 파일 모두를 복사합니다. \n",
        "            * 파일을 구분하기 위해 abnormal 파일들은 파일명 앞에 접두사 'ab_'를 붙입시다.\n",
        "        - os, shutil 모듈을 활용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVFQq5DE_qtC"
      },
      "outputs": [],
      "source": [
        "# copy 폴더 생성\n",
        "!mkdir /content/drive/MyDrive/Datasets/copy_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWIlebDxANYl"
      },
      "outputs": [],
      "source": [
        "# !mkdir /content/drive/MyDrive/Datasets/copy_images/trainset\n",
        "# !mkdir /content/drive/MyDrive/Datasets/copy_images/validset\n",
        "# !mkdir /content/drive/MyDrive/Datasets/copy_images/testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWts7VfT_up1"
      },
      "outputs": [],
      "source": [
        "# !mkdir /content/drive/MyDrive/Datasets/copy_images/trainset/normal; mkdir /content/drive/MyDrive/Datasets/copy_images/trainset/abnormal\n",
        "# !mkdir /content/drive/MyDrive/Datasets/copy_images/validset/normal; mkdir /content/drive/MyDrive/Datasets/copy_images/validset/abnormal\n",
        "# !mkdir /content/drive/MyDrive/Datasets/copy_images/testset/normal; mkdir /content/drive/MyDrive/Datasets/copy_images/testset/abnormal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UbNfTY4kOSZ"
      },
      "source": [
        "#### 1) abnormal 파일 복사"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhkKqLfTkjGI"
      },
      "source": [
        "* 복사하기 : shutil.copytree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTMVxJJJya98"
      },
      "outputs": [],
      "source": [
        "# 주의 shutil.copytree()를 사용할 때 해당 경로에 같은 이름의 파일이 있으면 오류남;; 경로에 파일 미리 만들기 X\n",
        "\n",
        "copy_test_ab_dir = '/content/drive/MyDrive/Datasets/copy_images/testset'\n",
        "copy_val_ab_dir = '/content/drive/MyDrive/Datasets/copy_images/validset'\n",
        "copy_train_ab_dir = '/content/drive/MyDrive/Datasets/copy_images/trainset'\n",
        "\n",
        "shutil.copytree(test_ab_dir, copy_test_ab_dir)\n",
        "shutil.copytree(val_ab_dir, copy_val_ab_dir)\n",
        "shutil.copytree(train_ab_dir, copy_train_ab_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU0T-ypHkV6D"
      },
      "source": [
        "* abnormal 이미지 이름의 접두어 \"ab_\" 붙이기 : os.rename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjWYxtFpCqJ-"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-69xZPaUCtjs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv6gafRyz6ul"
      },
      "outputs": [],
      "source": [
        "# copy_image_testset의 abnormal 이름 변경\n",
        "for filename in os.listdir(copy_test_ab_dir):\n",
        "    rename = 'ab_' + filename\n",
        "    os.rename(os.path.join(copy_test_ab_dir, filename), os.path.join(copy_test_ab_dir, rename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqv-CpseUZth"
      },
      "outputs": [],
      "source": [
        "# copy_image_validset의 abnormal 이름 변경\n",
        "for filename in os.listdir(copy_val_ab_dir):\n",
        "    rename = 'ab_' + filename\n",
        "    os.rename(os.path.join(copy_val_ab_dir, filename), os.path.join(copy_val_ab_dir, rename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9bQjBB-UZyx"
      },
      "outputs": [],
      "source": [
        "# copy_image_trainset의 abnormal 이름 변경\n",
        "for filename in os.listdir(copy_train_ab_dir):\n",
        "    rename = 'ab_' + filename\n",
        "    os.rename(os.path.join(copy_train_ab_dir, filename), os.path.join(copy_train_ab_dir, rename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "486FvfKlg_GD",
        "outputId": "29d13c09-f5ed-4f05-df84-7866b8ce0c43"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-57a614f65b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 이동동 후 데이터 크기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'copy_test: {len(os.listdir(copy_test_ab_dir))}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'copy_val: {len(os.listdir(copy_val_ab_dir))}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'copy_train: {len(os.listdir(copy_train_ab_dir))}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'copy_test_ab_dir' is not defined"
          ]
        }
      ],
      "source": [
        "# 이동동 후 데이터 크기\n",
        "print(f'copy_test: {len(os.listdir(copy_test_ab_dir))}')\n",
        "print(f'copy_val: {len(os.listdir(copy_val_ab_dir))}')\n",
        "print(f'copy_train: {len(os.listdir(copy_train_ab_dir))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk6xITmTksyK"
      },
      "source": [
        "#### 2) normal 파일 복사"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9Cb__08iwxc"
      },
      "outputs": [],
      "source": [
        "# test 파일을 이동\n",
        "# 복사사할 파일 리스트를 files에 저장\n",
        "files = os.listdir(test_nor_dir)\n",
        "\n",
        "for file in files:\n",
        "    source_path = os.path.join(test_nor_dir, file)\n",
        "    target_path = os.path.join(copy_test_nor_dir, file)\n",
        "    shutil.copy(source_path, target_path)\n",
        "\n",
        "# val 파일을 이동\n",
        "# 복사사할 파일 리스트를 files에 저장\n",
        "files = os.listdir(val_nor_dir)\n",
        "\n",
        "for file in files:\n",
        "    source_path = os.path.join(val_nor_dir, file)\n",
        "    target_path = os.path.join(copy_val_nor_dir, file)\n",
        "    shutil.copy(source_path, target_path)\n",
        "\n",
        "# train 파일을 이동\n",
        "# 복사사할 파일 리스트를 files에 저장\n",
        "files = os.listdir(train_nor_dir)\n",
        "\n",
        "for file in files:\n",
        "    source_path = os.path.join(train_nor_dir, file)\n",
        "    target_path = os.path.join(copy_train_nor_dir, file)\n",
        "    shutil.copy(source_path, target_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFwi0-hjGLZ9"
      },
      "outputs": [],
      "source": [
        "a = os.listdir('/content/drive/MyDrive/Datasets/copy_images/testset')\n",
        "b = os.listdir('/content/drive/MyDrive/Datasets/copy_images/trainset')\n",
        "c = os.listdir('/content/drive/MyDrive/Datasets/copy_images/validset')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmg8ptJpC4g_"
      },
      "outputs": [],
      "source": [
        "random.seed(2023)\n",
        "random.shuffle(a)\n",
        "random.shuffle(b)\n",
        "random.shuffle(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX67XixIGMFT",
        "outputId": "47f25a5d-1c9f-4817-e25a-e2139ba4d2c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['DALLбдE 2023-03-10 18.52.13 - photo of a part of car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.25.20 - slightly scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.46.21 - scratched car.png']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzEXHZrqkz88"
      },
      "source": [
        "* 데이터 갯수 조회"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "H0tw2_AonbeN",
        "outputId": "eeef584c-3e34-4db1-839f-bf13a1254f24"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-94426fe2ac4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'copy_images/trainset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'copy_images/validset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'copy_images/testset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_path' is not defined"
          ]
        }
      ],
      "source": [
        "print('train:', len(os.listdir(dataset_path+'copy_images/trainset/')))\n",
        "print('valid:', len(os.listdir(dataset_path+'copy_images/validset/')))\n",
        "print('test:', len(os.listdir(dataset_path+'copy_images/testset/')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfYDW1Pj7ZdU"
      },
      "source": [
        "## 3.모델링 I\n",
        "* **세부요구사항**\n",
        "    * 모델링을 위한 데이터 구조 만들기\n",
        "        * x : 이미지를 array로 변환합니다.\n",
        "        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n",
        "    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n",
        "        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n",
        "        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n",
        "        * Early Stopping을 반드시 사용하세요.\n",
        "            * 최적의 가중치를 모델에 적용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg553KIvxE6W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIfqg6e0xE6A"
      },
      "source": [
        "### (1) X : image to array\n",
        "- **세부요구사항**\n",
        "    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n",
        "    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다. \n",
        "    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n",
        "        * 각 폴더로 부터 이미지 목록을 만들고\n",
        "        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n",
        "            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n",
        "            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n",
        "            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n",
        "        * 데이터셋에 추가합니다.(데이터셋도 array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FovkIeSDT367"
      },
      "source": [
        "#### 1) 이미지 목록 만들기\n",
        "* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X022f0QMxE6W"
      },
      "outputs": [],
      "source": [
        "# # 이미지 목록 저장\n",
        "img_train_list = os.listdir(dataset_path+'copy_images/trainset/')\n",
        "img_valid_list = os.listdir(dataset_path+'copy_images/validset/')\n",
        "img_test_list = os.listdir(dataset_path+'copy_images/testset/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgvW_LQfxE6X"
      },
      "outputs": [],
      "source": [
        "# # 메모리, 처리시간을 위해서 이미지 크기 조정\n",
        "img_size = 280 ## 사이즈 조정 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSt88mjPV33u"
      },
      "source": [
        "#### 2) 이미지들을 배열 데이터셋으로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-SSN4Poo7T5",
        "outputId": "657dc162-1e00-488b-902d-e1b447a1a652"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ab_DALLбдE 2023-03-11 15.13.48 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.32.25 - a little bit scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.28.30 - photo of a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.28.29 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-10 22.37.56 - photo of a part of car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.59.32 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 00.12.34 - a part of car without scrach.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.16.50 - damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.42.01 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.07.10 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.41.54 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.46.26 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.29.53 - a little bit scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.43.01 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.12.25 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.21.50 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.26.11 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 00.14.28 - a part of car without scratch.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.58.57 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.59.08 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.04.26 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.13.45 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.48.31 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.07.12 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.15.54 - damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.54.14 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.30.50 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.53.58 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 00.48.34 - photo of a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.14.17 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.37.30 - photo of a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.43.03 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.08.30 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.49.59 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.34.52 - photo of a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.05.50 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.08.28 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.56.59 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.31.29 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.44.11 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.44.56 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.12.55 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.16.53 - damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.30.04 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.32.23 - a little bit scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.42.57 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.52.52 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.15.22 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.53.52 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 00.14.22 - a part of car without scratch.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.18.51 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.07.39 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.10.30 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.45.52 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.09.35 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 22.04.39 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.58.06 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.03.31 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.11.33 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.17.58 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.10.43 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.18.04 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.28.31 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.29.08 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.51.19 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.23.56 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.05.23 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.04.50 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.53.08 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.00.43 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.57.51 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.51.32 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.30.43 - a little bit scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.10.32 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.58.38 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.54.24 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.54.17 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.50.04 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.27.56 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.45.54 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.26.17 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.31.37 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.39.41 - photo of a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.09.13 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.16.24 - damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.25.14 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.08.48 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.06.15 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.25.12 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.18.49 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.18.02 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.54.42 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.15.58 - damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.43.36 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.51.24 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.32.21 - a little bit scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.24.55 - damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.29.06 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.55.00 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.31.55 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.44.30 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.45.32 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.42.59 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.21.52 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.25.08 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.49.42 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.12.28 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.45.06 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.28.25 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.50.45 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.05.44 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.09.57 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.11.06 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.48.35 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.16.04 - damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.22.16 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.49.06 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.17.37 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.18.25 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.22.27 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.02.20 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.26.14 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.31.38 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.30.49 - a little bit scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.12.06 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.25.10 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.59.10 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.18.31 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.12.50 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 00.04.45 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.49.08 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.59.49 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.46.22 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.44.16 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.14.15 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.24.02 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.42.32 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.41.32 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.23.58 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.57.28 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.30.04 - photo of a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.05.16 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.13.25 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.14.21 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.25.22 - slightly scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-10 22.04.44 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.50.01 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 00.16.36 - photo of a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.49.36 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.27.04 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.45.56 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.51.26 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.13.52 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.56.57 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.24.01 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.43.29 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.22.20 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.09.59 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.33.00 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.00.21 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.30.59 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.00.14 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.09.38 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.52.54 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.18.00 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.10.23 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.57.49 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.49.39 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.17.32 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.08.00 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.46.36 - photo of a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.03.37 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.50.39 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.17.27 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.05.46 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.53.49 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.30.45 - a little bit scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.22.25 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.55.09 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.57.31 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.17.35 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.55.32 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.14.19 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.01.31 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.18.29 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.06.41 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 23.59.42 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.10.25 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.54.38 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.10.34 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.31.20 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.48.33 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.49.32 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.55.03 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.51.29 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.28.33 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.55.34 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.22.18 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.54.42 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.21.46 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.44.13 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.49.03 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 15.06.35 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.52.56 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 00.03.13 - a part of car without blemish.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.42.29 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.45.28 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.21.48 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.29.03 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 14.56.30 - dents of a car.png',\n",
              " 'ab_DALLбдE 2023-03-11 18.42.27 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.26.12 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-10 18.54.19 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.30.01 - slightly dented car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.23.26 - slightly damaged car.png',\n",
              " 'ab_DALLбдE 2023-03-11 17.15.29 - scratched car.png',\n",
              " 'ab_DALLбдE 2023-03-11 01.32.19 - a little bit scratched car.png',\n",
              " 'DALLбдE 2023-03-11 14.45.14 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-10 22.22.55 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.22.47 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.41.18 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.18.21 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.04.26 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.14.11 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.22.54 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.06.36 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 01.06.32 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.35.41 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 17.09.48 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.39.49 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.14.39 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.32.47 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.30.55 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.25.48 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.33.41 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.37.37 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.33.14 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.42.03 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-10 18.52.44 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.17.19 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.28.18 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 00.32.49 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.14.42 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.26.16 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.04.23 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.57.59 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 22.22.48 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 22.23.20 - photo of a part of clean car.png',\n",
              " 'DALLбдE 2023-03-11 01.18.02 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.42.03 - photo of part of a car (1).png',\n",
              " 'DALLбдE 2023-03-11 14.44.52 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 17.08.32 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.39.23 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.34.11 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.55.45 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.41.37 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.42.05 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.37.15 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.40.47 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.35.05 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.41.11 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.25.21 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.34.16 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.15.06 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.59.32 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.36.44 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.31.23 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 22.23.54 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.58.53 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 18.50.18 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 01.18.05 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.42.09 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.43.06 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.35.46 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.44.02 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.25.07 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.25.52 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.12.34 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.35.37 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.07.42 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.36.19 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.35.43 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.25.00 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.01.47 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.31.06 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.12.37 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.02.41 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 18.50.29 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.04.36 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.01.20 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.43.32 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.28.24 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 18.52.40 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.55.59 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 00.51.38 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.45.10 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.01.51 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.36.24 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.31.26 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 22.22.18 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.18.51 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.30.53 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.16.06 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.07.52 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.40.52 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.31.51 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 17.08.47 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.36.22 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.16.08 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.13.37 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.16.12 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.34.56 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.35.40 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.51.24 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 00.57.21 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.32.41 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.20.46 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-10 22.37.34 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.32.32 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 22.07.07 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.29.28 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.38.51 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.13.06 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.04.49 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 18.52.17 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 18.50.25 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.41.20 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.20.48 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.51.44 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.18.25 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 00.21.24 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.35.09 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.27.50 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.26.42 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.34.58 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.39.17 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.43.02 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.25.42 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.12.31 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.28.22 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.15.38 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.29.47 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.01.17 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.41.41 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.22.58 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.29.56 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 00.21.18 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.32.22 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.34.47 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.36.06 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.14.06 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.32.34 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.52.28 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.33.26 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.42.04 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.33.16 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.58.50 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.34.21 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.02.14 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.23.33 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.28.57 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.16.30 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.36.16 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.43.01 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 18.50.11 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 01.15.24 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.31.12 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 00.25.03 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.36.08 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.32.16 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.37.09 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.20.04 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 00.52.55 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.32.47 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 22.07.10 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.58.44 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.18.48 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.01.22 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 01.18.07 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.24.54 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.24.04 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.33.23 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.41.16 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.00.10 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.46.24 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.07.48 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.29.21 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.35.30 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.31.15 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.28.25 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.16.31 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.39.44 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.23.27 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.02.38 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-10 23.37.20 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.24.58 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.34.23 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.15.43 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.49.10 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.41.40 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.12.33 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.20.44 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.32.01 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.33.43 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.04.47 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 14.13.42 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.38.19 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.34.18 - photo of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.18.27 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.23.36 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.05.30 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.15.04 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.36.49 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.15.18 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.26.52 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 00.21.21 - photo of a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.49.38 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.56.41 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 14.15.40 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.14.09 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.40.50 - photo of part of a car.png',\n",
              " 'DALLбдE 2023-03-11 01.14.11 - a part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.24.16 - part of a car.png',\n",
              " 'DALLбдE 2023-03-11 14.15.09 - part of a car.png',\n",
              " 'DALLбдE 2023-03-10 23.55.54 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 18.52.35 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 01.02.44 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 01.01.49 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.04.04 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 22.22.12 - photo of a part of car.png',\n",
              " 'DALLбдE 2023-03-11 00.05.29 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-10 23.55.49 - a part of car without blemish.png',\n",
              " 'DALLбдE 2023-03-11 01.36.02 - photo of a car.png']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_train_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWvl4LHlrZA6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "import numpy as np\n",
        "import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q-GzbPHPmGk"
      },
      "outputs": [],
      "source": [
        "img_train_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElORdepFo7Zk"
      },
      "outputs": [],
      "source": [
        "copy_files_train = glob.glob('/content/drive/MyDrive/Datasets/copy_images/trainset/*')\n",
        "train_path = '/content/drive/MyDrive/Datasets/copy_images/trainset/'\n",
        "images = []\n",
        "for file in img_train_list:\n",
        "    img = image.load_img(train_path + file, target_size=(280,280))\n",
        "    img = image.img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "    images.append(img)\n",
        "x_train = np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXLYTjKDo7zU"
      },
      "outputs": [],
      "source": [
        "copy_files_val = glob.glob('/content/drive/MyDrive/Datasets/copy_images/validset/*')\n",
        "val_path = '/content/drive/MyDrive/Datasets/copy_images/validset/'\n",
        "images = []\n",
        "for file in img_valid_list:\n",
        "    img = image.load_img(val_path + file, target_size=(280,280))\n",
        "    img = image.img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "    images.append(img)\n",
        "x_val = np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNJJyjKPo76L"
      },
      "outputs": [],
      "source": [
        "copy_files_test = glob.glob('/content/drive/MyDrive/Datasets/copy_images/testset/*')\n",
        "test_path = '/content/drive/MyDrive/Datasets/copy_images/testset/'\n",
        "images = []\n",
        "for file in img_test_list:\n",
        "    img = image.load_img(test_path + file, target_size=(280,280))\n",
        "    img = image.img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "    images.append(img)\n",
        "x_test = np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNMJzEKwo8Az",
        "outputId": "703894c9-114f-407b-cd2d-f98d12f6d4f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((433, 280, 280, 3), (110, 280, 280, 3), (62, 280, 280, 3))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_val.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-glSxo-Dq7RD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doUM37LxxE6Z"
      },
      "source": [
        "### (2) y : 클래스 만들기\n",
        "- **세부요구사항**\n",
        "    - Training set / Validation set / Test set의 y를 생성합니다.\n",
        "        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n",
        "        - normal을 0, abnormal을 1로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nl1Uv9UxE6b",
        "outputId": "d0a86f37-40fc-4e07-a39d-9660d061127f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "433\n",
            "217\n",
            "---\n",
            "110\n",
            "55\n",
            "---\n",
            "62\n",
            "31\n"
          ]
        }
      ],
      "source": [
        "# 데이터 갯수 확인\n",
        "print( len(img_train_list) )\n",
        "print( len([val for val in img_train_list if val.startswith('ab_')]) )\n",
        "print('---')\n",
        "print( len(img_valid_list) )\n",
        "print( len([val for val in img_valid_list if val.startswith('ab_')]) )\n",
        "print('---')\n",
        "print( len(img_test_list) )\n",
        "print( len([val for val in img_test_list if val.startswith('ab_')]) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfaCLlNn04C"
      },
      "source": [
        "* y_train, y_valid, y_test 만들기\n",
        "    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD9syLe9xqGh",
        "outputId": "0ed60987-484c-4919-b359-c907801067c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-11 15.13.48 - dents of a car.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-11 01.32.25 - a little bit scratched car.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-10 23.28.30 - photo of a part of car without blemish.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-11 17.28.29 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-10 22.37.56 - photo of a part of car.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-11 14.59.32 - dents of a car.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-11 00.12.34 - a part of car without scrach.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-11 17.16.50 - damaged car.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-11 18.42.01 - slightly dented car.png',\n",
              " '/content/drive/MyDrive/Datasets/copy_images/trainset/ab_DALLбдE 2023-03-11 15.07.10 - dents of a car.png']"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "copy_files_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVrPQdhTxE6b"
      },
      "outputs": [],
      "source": [
        "# y_train\n",
        "temp = []\n",
        "for i in img_train_list:\n",
        "    if i.startswith('ab_'):\n",
        "        temp.append(1)\n",
        "    else:\n",
        "        temp.append(0)\n",
        "y_train = np.array(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hSByezUMA8L",
        "outputId": "46194d15-28d4-4a51-e216-10159a9aa22f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEmDw8TWKinM",
        "outputId": "ec2755a9-441b-4967-ab71-55c3af70a7d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjFFI_qwy64x"
      },
      "outputs": [],
      "source": [
        "# y_valid\n",
        "temp = []\n",
        "for i in img_valid_list:\n",
        "    if i.startswith('ab_'):\n",
        "        temp.append(1)\n",
        "    else:\n",
        "        temp.append(0)\n",
        "y_val = np.array(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkNRdRyrzFe6"
      },
      "outputs": [],
      "source": [
        "# y_test\n",
        "temp = []\n",
        "for i in img_test_list:\n",
        "    if i.startswith('ab_'):\n",
        "        temp.append(1)\n",
        "    else:\n",
        "        temp.append(0)\n",
        "y_test = np.array(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYZMn-iu5oNb"
      },
      "outputs": [],
      "source": [
        "# Scaling 표준화화\n",
        "mean_n = x_train.mean()\n",
        "std_n = x_train.std()\n",
        "\n",
        "x_train_sc = (x_train - mean_n) / std_n\n",
        "x_test_sc = (x_test - mean_n) / std_n\n",
        "x_val_sc = (x_val - mean_n) / std_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am4Wwx6eMC8G"
      },
      "outputs": [],
      "source": [
        "# Scaling MinMax\n",
        "x_max, x_min = x_train.max(), x_train.min()\n",
        "x_train_mi = (x_train                                                                                                                                                                                                                                                                                                                                                                                                                                                                      - x_max)/(x_max - x_min)\n",
        "x_test_mi = (x_test - x_max)/(x_max - x_min)\n",
        "x_val_mi = (x_val - x_max)/(x_max - x_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbmx-lFq8B2Z"
      },
      "outputs": [],
      "source": [
        "# one-hot Encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "class_n = len(np.unique(y_train))\n",
        "y_train = to_categorical(y_train, class_n)\n",
        "y_val = to_categorical(y_val, class_n)\n",
        "y_test = to_categorical(y_test, class_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1-OJVYD-IYY",
        "outputId": "5fb38f64-e45f-4020-bf83-1a211c7873b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.], dtype=float32)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqxVIzd9zLJj",
        "outputId": "de00497f-5f27-484e-f566-1be70bb64eb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((433, 2), (110, 2), (62, 2))"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_val.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z586wXFu7ZgT"
      },
      "source": [
        "### (3) 모델1\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRoL-RzL0NQT",
        "outputId": "a5621954-1fe5-47ce-93b4-a7b28eaa4817"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((433, 280, 280, 3), (433, 2))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIvIO6RKa0mp"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TtIIz6XJQ5E"
      },
      "outputs": [],
      "source": [
        "# Functional API\n",
        "\n",
        "# 라이브러리\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 세션클리어\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# layer 연결\n",
        "il = keras.layers.Input(shape=(280, 280, 3))\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu')(il)\n",
        "hl = keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Flatten()(hl)\n",
        "\n",
        "hl = keras.layers.Dense(64, activation='relu')(hl)\n",
        "hl = keras.layers.Dense(32, activation='relu')(hl)\n",
        "hl = keras.layers.Dropout(0.3)(hl)\n",
        "ol = keras.layers.Dense(2, activation='sigmoid')(hl)\n",
        "\n",
        "# 모델 생성\n",
        "model = keras.Model(il, ol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4XilGUzRAIw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_Ru4TxX2-yO",
        "outputId": "1bb351a0-c28f-4c02-84bd-def96bd43999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 278, 278, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 276, 276, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 276, 276, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 138, 138, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 138, 138, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 136, 136, 64)      18496     \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 134, 134, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 134, 134, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 67, 67, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 67, 67, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 67, 67, 128)       131200    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 67, 67, 128)       262272    \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 67, 67, 128)       262272    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 33, 33, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 33, 33, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 33, 33, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 33, 33, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 33, 33, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 128)       295040    \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,361,954\n",
            "Trainable params: 3,360,738\n",
            "Non-trainable params: 1,216\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 모델 컴파일\n",
        "model.compile(loss=keras.losses.binary_crossentropy, metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# 요약\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHM91_bha3Kc"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHnFVZuKa42f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnrTSupKa42f",
        "outputId": "26443945-6bf2-4d95-ec0c-acd64f3c3155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "14/14 [==============================] - 35s 982ms/step - loss: 0.6871 - accuracy: 0.7021 - val_loss: 1.2007 - val_accuracy: 0.5000\n",
            "Epoch 2/10000\n",
            "14/14 [==============================] - 6s 454ms/step - loss: 0.5178 - accuracy: 0.8060 - val_loss: 0.6645 - val_accuracy: 0.6273\n",
            "Epoch 3/10000\n",
            "14/14 [==============================] - 7s 476ms/step - loss: 0.4430 - accuracy: 0.8383 - val_loss: 1.2135 - val_accuracy: 0.4818\n",
            "Epoch 4/10000\n",
            "14/14 [==============================] - 7s 470ms/step - loss: 0.4339 - accuracy: 0.8545 - val_loss: 0.8682 - val_accuracy: 0.6182\n",
            "Epoch 5/10000\n",
            "14/14 [==============================] - 6s 451ms/step - loss: 0.3318 - accuracy: 0.8637 - val_loss: 1.6990 - val_accuracy: 0.6182\n",
            "Epoch 6/10000\n",
            "14/14 [==============================] - 6s 464ms/step - loss: 0.3528 - accuracy: 0.8406 - val_loss: 0.8664 - val_accuracy: 0.4727\n",
            "Epoch 7/10000\n",
            "14/14 [==============================] - 6s 462ms/step - loss: 0.3363 - accuracy: 0.8614 - val_loss: 0.8094 - val_accuracy: 0.7636\n",
            "Epoch 8/10000\n",
            "14/14 [==============================] - 6s 441ms/step - loss: 0.2604 - accuracy: 0.8915 - val_loss: 1.2974 - val_accuracy: 0.6727\n",
            "Epoch 9/10000\n",
            "14/14 [==============================] - 6s 441ms/step - loss: 0.2198 - accuracy: 0.9192 - val_loss: 2.2602 - val_accuracy: 0.6727\n",
            "Epoch 10/10000\n",
            "14/14 [==============================] - 6s 458ms/step - loss: 0.2211 - accuracy: 0.9192 - val_loss: 1.0391 - val_accuracy: 0.6818\n",
            "Epoch 11/10000\n",
            "14/14 [==============================] - 6s 444ms/step - loss: 0.2451 - accuracy: 0.9030 - val_loss: 0.6322 - val_accuracy: 0.7636\n",
            "Epoch 12/10000\n",
            "14/14 [==============================] - 6s 442ms/step - loss: 0.2056 - accuracy: 0.9261 - val_loss: 0.9263 - val_accuracy: 0.7818\n",
            "Epoch 13/10000\n",
            "14/14 [==============================] - 6s 461ms/step - loss: 0.1382 - accuracy: 0.9538 - val_loss: 4.5731 - val_accuracy: 0.6273\n",
            "Epoch 14/10000\n",
            "14/14 [==============================] - 6s 445ms/step - loss: 0.1443 - accuracy: 0.9469 - val_loss: 3.2993 - val_accuracy: 0.6455\n",
            "Epoch 15/10000\n",
            "14/14 [==============================] - 6s 447ms/step - loss: 0.1310 - accuracy: 0.9423 - val_loss: 2.3768 - val_accuracy: 0.6545\n",
            "Epoch 16/10000\n",
            "14/14 [==============================] - 6s 444ms/step - loss: 0.1012 - accuracy: 0.9677 - val_loss: 1.9246 - val_accuracy: 0.6909\n",
            "Epoch 17/10000\n",
            "14/14 [==============================] - 6s 465ms/step - loss: 0.0879 - accuracy: 0.9700 - val_loss: 2.0062 - val_accuracy: 0.7455\n",
            "Epoch 18/10000\n",
            "14/14 [==============================] - 6s 463ms/step - loss: 0.0920 - accuracy: 0.9700 - val_loss: 1.2578 - val_accuracy: 0.6818\n",
            "Epoch 19/10000\n",
            "14/14 [==============================] - 6s 445ms/step - loss: 0.0811 - accuracy: 0.9700 - val_loss: 1.2594 - val_accuracy: 0.6909\n",
            "Epoch 20/10000\n",
            "14/14 [==============================] - 6s 463ms/step - loss: 0.0750 - accuracy: 0.9746 - val_loss: 2.2270 - val_accuracy: 0.7091\n",
            "Epoch 21/10000\n",
            "14/14 [==============================] - 6s 463ms/step - loss: 0.1228 - accuracy: 0.9654 - val_loss: 5.2077 - val_accuracy: 0.6636\n",
            "Epoch 22/10000\n",
            "14/14 [==============================] - 6s 443ms/step - loss: 0.0890 - accuracy: 0.9677 - val_loss: 5.6117 - val_accuracy: 0.7000\n",
            "Epoch 23/10000\n",
            "14/14 [==============================] - 6s 464ms/step - loss: 0.0823 - accuracy: 0.9746 - val_loss: 1.3477 - val_accuracy: 0.7455\n",
            "Epoch 24/10000\n",
            "14/14 [==============================] - 6s 460ms/step - loss: 0.0483 - accuracy: 0.9931 - val_loss: 1.1387 - val_accuracy: 0.8818\n",
            "Epoch 25/10000\n",
            "14/14 [==============================] - 6s 461ms/step - loss: 0.0866 - accuracy: 0.9654 - val_loss: 1.7516 - val_accuracy: 0.7182\n",
            "Epoch 26/10000\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9492Restoring model weights from the end of the best epoch: 11.\n",
            "14/14 [==============================] - 6s 445ms/step - loss: 0.1555 - accuracy: 0.9492 - val_loss: 1.3755 - val_accuracy: 0.6364\n",
            "Epoch 26: early stopping\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10000, verbose=1, callbacks=[es])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zage6-Z0a6DX"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xkFFlFdbBZb",
        "outputId": "9a3c0c71-d652-442b-ca1a-6d6257e631c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 3s 2s/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test_sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru5hgJNsNsIb",
        "outputId": "4a49a5df-ebff-4509-dbe0-79544b42097a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(62, 2)"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-EQFVkCbBZc",
        "outputId": "702b67e0-6599-4f55-856c-91fe1538a317"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(62,)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_new = y_pred.argmax(axis=1)\n",
        "y_pred_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDGRin1jODG4",
        "outputId": "6aa71f39-913d-4b97-ae5d-aa732dae9528"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(62, 2)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uHElX-uOJvT",
        "outputId": "c83e75f1-f3d7-4981-9322-524d014c3b2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(62,)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_new = y_test.argmax(axis=1)\n",
        "y_test_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmfy7P2KOR1r",
        "outputId": "3c0123f6-e506-49af-df51-209fa6bcb690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.68      0.62        31\n",
            "           1       0.60      0.48      0.54        31\n",
            "\n",
            "    accuracy                           0.58        62\n",
            "   macro avg       0.58      0.58      0.58        62\n",
            "weighted avg       0.58      0.58      0.58        62\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'{classification_report(y_test_new, y_pred_new)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRoacK2mcLPb"
      },
      "source": [
        "### (4) 모델2\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WTwG8NFoLBQ"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHu5gey1oLBR",
        "outputId": "f7e5d401-d374-4e21-f581-080637a80a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 280, 280, 64)      4864      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 140, 140, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 140, 140, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 140, 140, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 140, 140, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 140, 140, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 70, 70, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 70, 70, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 70, 70, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 70, 70, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 70, 70, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 35, 35, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 35, 35, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 29, 29, 128)       262272    \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 29, 29, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 29, 29, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 29, 29, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 29, 29, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 29, 29, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 14, 14, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 14, 14, 128)       295040    \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                401472    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,780,386\n",
            "Trainable params: 3,778,978\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Functional API\n",
        "\n",
        "# 라이브러리\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 세션클리어\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# layer 연결\n",
        "il = keras.layers.Input(shape=(280, 280, 3))\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu')(il)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Flatten()(hl)\n",
        "\n",
        "hl = keras.layers.Dense(64, activation='relu')(hl)\n",
        "hl = keras.layers.Dense(32, activation='relu')(hl)\n",
        "hl = keras.layers.Dropout(0.3)(hl)\n",
        "ol = keras.layers.Dense(2, activation='sigmoid')(hl)\n",
        "\n",
        "# 모델 생성\n",
        "model2 = keras.Model(il, ol)\n",
        "\n",
        "# 모델 컴파일\n",
        "model2.compile(loss=keras.losses.binary_crossentropy, metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# 요약\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqTzgRTroLBR"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcVDXnpQoLBR",
        "outputId": "077ce28f-321a-49ea-f561-5134c3049807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.1074 - accuracy: 0.9654 - val_loss: 8.8294 - val_accuracy: 0.6818\n",
            "Epoch 2/10000\n",
            "14/14 [==============================] - 4s 320ms/step - loss: 0.1172 - accuracy: 0.9654 - val_loss: 9.3490 - val_accuracy: 0.6455\n",
            "Epoch 3/10000\n",
            "14/14 [==============================] - 5s 347ms/step - loss: 0.1403 - accuracy: 0.9538 - val_loss: 5.2631 - val_accuracy: 0.6273\n",
            "Epoch 4/10000\n",
            "14/14 [==============================] - 5s 324ms/step - loss: 0.2260 - accuracy: 0.9053 - val_loss: 14.9209 - val_accuracy: 0.5818\n",
            "Epoch 5/10000\n",
            "14/14 [==============================] - 5s 323ms/step - loss: 0.1782 - accuracy: 0.9400 - val_loss: 29.4966 - val_accuracy: 0.5091\n",
            "Epoch 6/10000\n",
            "14/14 [==============================] - 5s 348ms/step - loss: 0.2253 - accuracy: 0.9145 - val_loss: 40.2655 - val_accuracy: 0.5909\n",
            "Epoch 7/10000\n",
            "14/14 [==============================] - 5s 326ms/step - loss: 0.2297 - accuracy: 0.8938 - val_loss: 22.3192 - val_accuracy: 0.6727\n",
            "Epoch 8/10000\n",
            "14/14 [==============================] - 5s 324ms/step - loss: 0.2249 - accuracy: 0.9169 - val_loss: 35.7474 - val_accuracy: 0.6000\n",
            "Epoch 9/10000\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.1162 - accuracy: 0.9561 - val_loss: 18.8454 - val_accuracy: 0.7182\n",
            "Epoch 10/10000\n",
            "14/14 [==============================] - 5s 325ms/step - loss: 0.1273 - accuracy: 0.9515 - val_loss: 12.2833 - val_accuracy: 0.7636\n",
            "Epoch 11/10000\n",
            "14/14 [==============================] - 5s 325ms/step - loss: 0.1035 - accuracy: 0.9677 - val_loss: 9.1304 - val_accuracy: 0.7455\n",
            "Epoch 12/10000\n",
            "14/14 [==============================] - 5s 354ms/step - loss: 0.0562 - accuracy: 0.9885 - val_loss: 4.1845 - val_accuracy: 0.8273\n",
            "Epoch 13/10000\n",
            "14/14 [==============================] - 5s 349ms/step - loss: 0.0550 - accuracy: 0.9838 - val_loss: 5.1745 - val_accuracy: 0.8091\n",
            "Epoch 14/10000\n",
            "14/14 [==============================] - 5s 354ms/step - loss: 0.0589 - accuracy: 0.9838 - val_loss: 3.0478 - val_accuracy: 0.8000\n",
            "Epoch 15/10000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0600 - accuracy: 0.9815 - val_loss: 2.4567 - val_accuracy: 0.8273\n",
            "Epoch 16/10000\n",
            "14/14 [==============================] - 5s 352ms/step - loss: 0.0694 - accuracy: 0.9769 - val_loss: 1.7864 - val_accuracy: 0.8455\n",
            "Epoch 17/10000\n",
            "14/14 [==============================] - 5s 358ms/step - loss: 0.0407 - accuracy: 0.9908 - val_loss: 1.2708 - val_accuracy: 0.8364\n",
            "Epoch 18/10000\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0395 - accuracy: 0.9908 - val_loss: 1.2852 - val_accuracy: 0.8636\n",
            "Epoch 19/10000\n",
            "14/14 [==============================] - 5s 352ms/step - loss: 0.0345 - accuracy: 0.9861 - val_loss: 3.8711 - val_accuracy: 0.7727\n",
            "Epoch 20/10000\n",
            "14/14 [==============================] - 5s 356ms/step - loss: 0.1237 - accuracy: 0.9677 - val_loss: 1.9510 - val_accuracy: 0.7818\n",
            "Epoch 21/10000\n",
            "14/14 [==============================] - 5s 352ms/step - loss: 0.1525 - accuracy: 0.9446 - val_loss: 1.4557 - val_accuracy: 0.8182\n",
            "Epoch 22/10000\n",
            "14/14 [==============================] - 5s 354ms/step - loss: 0.0786 - accuracy: 0.9700 - val_loss: 5.0605 - val_accuracy: 0.7636\n",
            "Epoch 23/10000\n",
            "14/14 [==============================] - 5s 352ms/step - loss: 0.1003 - accuracy: 0.9677 - val_loss: 4.5709 - val_accuracy: 0.7091\n",
            "Epoch 24/10000\n",
            "14/14 [==============================] - 5s 353ms/step - loss: 0.0359 - accuracy: 0.9931 - val_loss: 2.8356 - val_accuracy: 0.8182\n",
            "Epoch 25/10000\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0454 - accuracy: 0.9861 - val_loss: 2.6402 - val_accuracy: 0.8364\n",
            "Epoch 26/10000\n",
            "14/14 [==============================] - 5s 353ms/step - loss: 0.0683 - accuracy: 0.9792 - val_loss: 2.2066 - val_accuracy: 0.7909\n",
            "Epoch 27/10000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0298 - accuracy: 0.9931 - val_loss: 2.0520 - val_accuracy: 0.8455\n",
            "Epoch 28/10000\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0518 - accuracy: 0.9792 - val_loss: 2.2168 - val_accuracy: 0.8364\n",
            "Epoch 29/10000\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0587 - accuracy: 0.9861 - val_loss: 2.6700 - val_accuracy: 0.8091\n",
            "Epoch 30/10000\n",
            "14/14 [==============================] - 5s 336ms/step - loss: 0.1335 - accuracy: 0.9746 - val_loss: 5.3532 - val_accuracy: 0.7364\n",
            "Epoch 31/10000\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0781 - accuracy: 0.9723 - val_loss: 3.1073 - val_accuracy: 0.8364\n",
            "Epoch 32/10000\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9584Restoring model weights from the end of the best epoch: 17.\n",
            "14/14 [==============================] - 5s 360ms/step - loss: 0.1541 - accuracy: 0.9584 - val_loss: 5.4109 - val_accuracy: 0.7818\n",
            "Epoch 32: early stopping\n"
          ]
        }
      ],
      "source": [
        "hist2 = model2.fit(x_train_sc, y_train, validation_data=(x_val_sc, y_val), epochs=10000, verbose=1, callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAhXnGmXoLBS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZ0U7K1oLBS"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShruikbsoLBS",
        "outputId": "feca0370-8ed6-4f82-d289-ede53f74a428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 121ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred2 = model2.predict(x_test_sc)\n",
        "y_pred_new2 = y_pred2.argmax(axis=1)\n",
        "y_test_new2 = y_test.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8MC8l07oLBS",
        "outputId": "93fec17c-5ecb-42ec-9926-b0fd86b93a50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.77      0.76        31\n",
            "           1       0.77      0.74      0.75        31\n",
            "\n",
            "    accuracy                           0.76        62\n",
            "   macro avg       0.76      0.76      0.76        62\n",
            "weighted avg       0.76      0.76      0.76        62\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'{classification_report(y_test_new, y_pred_new2)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7FVsFiCFSGa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRqzBw8eccwj"
      },
      "source": [
        "### (5) 모델3\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 validation_data로 validation set을 사용하시오.\n",
        "    - 반드시 Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtNd8u5RoNJo"
      },
      "source": [
        "#### 1) 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM-Npn6WoNJo",
        "outputId": "d4b31b74-7926-4064-8798-855a4d6c629f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 280, 280, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 280, 280, 64)      3136      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 140, 140, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 140, 140, 64)      65600     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 140, 140, 64)      65600     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 140, 140, 64)      65600     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 70, 70, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 70, 70, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 70, 70, 128)       131200    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 70, 70, 128)       262272    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 70, 70, 128)       262272    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 627200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                40140864  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,996,930\n",
            "Trainable params: 40,996,802\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Functional API\n",
        "\n",
        "# 라이브러리\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 세션클리어\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# layer 연결\n",
        "il = keras.layers.Input(shape=(280, 280, 3))\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(il)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.MaxPool2D(pool_size=(2,2))(hl)\n",
        "hl = keras.layers.BatchNormalization()(hl)\n",
        "\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "hl = keras.layers.Conv2D(filters=128, kernel_size=(4,4), strides=(1,1), padding='same', activation='relu')(hl)\n",
        "\n",
        "hl = keras.layers.Flatten()(hl)\n",
        "\n",
        "hl = keras.layers.Dense(64, activation='relu')(hl)\n",
        "hl = keras.layers.Dropout(0.25)(hl)\n",
        "ol = keras.layers.Dense(2, activation='sigmoid')(hl)\n",
        "\n",
        "# 모델 생성\n",
        "model3 = keras.Model(il, ol)\n",
        "\n",
        "# 모델 컴파일\n",
        "model3.compile(loss=keras.losses.binary_crossentropy, metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# 요약\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zgVkXLHoNJo"
      },
      "source": [
        "#### 2) 학습\n",
        "* EarlyStopping 설정하고 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTlUNbkhoNJo",
        "outputId": "ad61935d-80c3-484c-c4cc-90e380a76b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "14/14 [==============================] - 6s 398ms/step - loss: 0.6107 - accuracy: 0.7598 - val_loss: 0.6288 - val_accuracy: 0.6636\n",
            "Epoch 2/10000\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.4514 - accuracy: 0.8152 - val_loss: 0.7514 - val_accuracy: 0.5545\n",
            "Epoch 3/10000\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.4558 - accuracy: 0.8453 - val_loss: 0.8559 - val_accuracy: 0.5182\n",
            "Epoch 4/10000\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.4404 - accuracy: 0.8176 - val_loss: 0.7917 - val_accuracy: 0.5818\n",
            "Epoch 5/10000\n",
            "14/14 [==============================] - 5s 371ms/step - loss: 0.3611 - accuracy: 0.8614 - val_loss: 0.7723 - val_accuracy: 0.5818\n",
            "Epoch 6/10000\n",
            "14/14 [==============================] - 5s 371ms/step - loss: 0.3616 - accuracy: 0.8453 - val_loss: 2.8859 - val_accuracy: 0.5455\n",
            "Epoch 7/10000\n",
            "14/14 [==============================] - 5s 347ms/step - loss: 0.3764 - accuracy: 0.8591 - val_loss: 0.6723 - val_accuracy: 0.7091\n",
            "Epoch 8/10000\n",
            "14/14 [==============================] - 5s 372ms/step - loss: 0.3308 - accuracy: 0.8684 - val_loss: 0.6856 - val_accuracy: 0.7727\n",
            "Epoch 9/10000\n",
            "14/14 [==============================] - 5s 366ms/step - loss: 0.3043 - accuracy: 0.8591 - val_loss: 0.5172 - val_accuracy: 0.7909\n",
            "Epoch 10/10000\n",
            "14/14 [==============================] - 5s 371ms/step - loss: 0.3183 - accuracy: 0.8776 - val_loss: 0.9604 - val_accuracy: 0.7909\n",
            "Epoch 11/10000\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.2683 - accuracy: 0.8938 - val_loss: 0.9359 - val_accuracy: 0.7273\n",
            "Epoch 12/10000\n",
            "14/14 [==============================] - 5s 344ms/step - loss: 0.2235 - accuracy: 0.8961 - val_loss: 1.3498 - val_accuracy: 0.7273\n",
            "Epoch 13/10000\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.2310 - accuracy: 0.8915 - val_loss: 0.8079 - val_accuracy: 0.7909\n",
            "Epoch 14/10000\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.1760 - accuracy: 0.9169 - val_loss: 0.8541 - val_accuracy: 0.8091\n",
            "Epoch 15/10000\n",
            "14/14 [==============================] - 5s 367ms/step - loss: 0.1609 - accuracy: 0.9169 - val_loss: 1.5101 - val_accuracy: 0.7455\n",
            "Epoch 16/10000\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.1464 - accuracy: 0.9192 - val_loss: 0.8695 - val_accuracy: 0.8545\n",
            "Epoch 17/10000\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.2253 - accuracy: 0.8961 - val_loss: 0.8720 - val_accuracy: 0.8273\n",
            "Epoch 18/10000\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.2015 - accuracy: 0.9192 - val_loss: 1.0575 - val_accuracy: 0.7818\n",
            "Epoch 19/10000\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.1572 - accuracy: 0.9238 - val_loss: 1.0607 - val_accuracy: 0.8273\n",
            "Epoch 20/10000\n",
            "14/14 [==============================] - 5s 366ms/step - loss: 0.1549 - accuracy: 0.9261 - val_loss: 1.8379 - val_accuracy: 0.7273\n",
            "Epoch 21/10000\n",
            "14/14 [==============================] - 5s 369ms/step - loss: 0.2694 - accuracy: 0.9030 - val_loss: 0.6215 - val_accuracy: 0.7727\n",
            "Epoch 22/10000\n",
            "14/14 [==============================] - 5s 380ms/step - loss: 0.4120 - accuracy: 0.8845 - val_loss: 0.5049 - val_accuracy: 0.8182\n",
            "Epoch 23/10000\n",
            "14/14 [==============================] - 5s 348ms/step - loss: 0.2786 - accuracy: 0.8938 - val_loss: 1.0247 - val_accuracy: 0.5364\n",
            "Epoch 24/10000\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.2395 - accuracy: 0.8984 - val_loss: 2.2410 - val_accuracy: 0.6636\n",
            "Epoch 25/10000\n",
            "14/14 [==============================] - 5s 368ms/step - loss: 0.2770 - accuracy: 0.9053 - val_loss: 1.1738 - val_accuracy: 0.5909\n",
            "Epoch 26/10000\n",
            "14/14 [==============================] - 5s 344ms/step - loss: 0.2857 - accuracy: 0.8822 - val_loss: 0.9927 - val_accuracy: 0.6545\n",
            "Epoch 27/10000\n",
            "14/14 [==============================] - 5s 344ms/step - loss: 0.1924 - accuracy: 0.9261 - val_loss: 1.8599 - val_accuracy: 0.6000\n",
            "Epoch 28/10000\n",
            "14/14 [==============================] - 5s 370ms/step - loss: 0.1840 - accuracy: 0.9145 - val_loss: 2.0347 - val_accuracy: 0.6000\n",
            "Epoch 29/10000\n",
            "14/14 [==============================] - 5s 344ms/step - loss: 0.1412 - accuracy: 0.9284 - val_loss: 2.4182 - val_accuracy: 0.6273\n",
            "Epoch 30/10000\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.1557 - accuracy: 0.9238 - val_loss: 1.0141 - val_accuracy: 0.7545\n",
            "Epoch 31/10000\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.1635 - accuracy: 0.9353 - val_loss: 0.6062 - val_accuracy: 0.8091\n",
            "Epoch 32/10000\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.1438 - accuracy: 0.9307 - val_loss: 1.3271 - val_accuracy: 0.8091\n",
            "Epoch 33/10000\n",
            "14/14 [==============================] - 5s 367ms/step - loss: 0.1647 - accuracy: 0.9261 - val_loss: 1.0121 - val_accuracy: 0.8273\n",
            "Epoch 34/10000\n",
            "14/14 [==============================] - 5s 365ms/step - loss: 0.1506 - accuracy: 0.9376 - val_loss: 0.9104 - val_accuracy: 0.8091\n",
            "Epoch 35/10000\n",
            "14/14 [==============================] - 5s 366ms/step - loss: 0.1556 - accuracy: 0.9330 - val_loss: 0.6609 - val_accuracy: 0.8273\n",
            "Epoch 36/10000\n",
            "14/14 [==============================] - 5s 366ms/step - loss: 0.1387 - accuracy: 0.9376 - val_loss: 0.6504 - val_accuracy: 0.8455\n",
            "Epoch 37/10000\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.9469Restoring model weights from the end of the best epoch: 22.\n",
            "14/14 [==============================] - 5s 353ms/step - loss: 0.1436 - accuracy: 0.9469 - val_loss: 0.5473 - val_accuracy: 0.8273\n",
            "Epoch 37: early stopping\n"
          ]
        }
      ],
      "source": [
        "hist3 = model3.fit(x_train_sc, y_train, validation_data=(x_val_sc, y_val), epochs=10000, verbose=1, callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4GYo0dboNJo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZV9zbsroNJo"
      },
      "source": [
        "#### 3) test set으로 예측하고 평가하기\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc9UmjZ0oNJo",
        "outputId": "4325012d-6a61-4c33-cc2e-affc4ac1ed3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 108ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred3 = model3.predict(x_test_mi)\n",
        "y_pred_new3 = y_pred3.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP-p0_y9oNJo",
        "outputId": "890ce52b-8085-4d6f-e71e-b172f0676bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.77      0.75        31\n",
            "           1       0.76      0.71      0.73        31\n",
            "\n",
            "    accuracy                           0.74        62\n",
            "   macro avg       0.74      0.74      0.74        62\n",
            "weighted avg       0.74      0.74      0.74        62\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'{classification_report(y_test_new, y_pred_new3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE-8oEeOAg9e"
      },
      "source": [
        "### (6)모델4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAtnqob5AeKA"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Add, Flatten, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "def residual_block(x, filters, strides=(1,1), shortcut=None):\n",
        "    shortcut = x\n",
        "    x = Conv2D(filters, kernel_size=(3,3), strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def resnet(input_shape, n_classes):\n",
        "    input = Input(shape=input_shape)\n",
        "    \n",
        "    x = Conv2D(64, kernel_size=(7,7), strides=(2,2), padding='same')(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
        "    \n",
        "    x = residual_block(x, filters=64, strides=(1,1))\n",
        "    x = residual_block(x, filters=64, strides=(1,1))\n",
        "    x = residual_block(x, filters=64, strides=(1,1))\n",
        "    \n",
        "    x = residual_block(x, filters=128, strides=(2,2))\n",
        "    x = residual_block(x, filters=128, strides=(1,1))\n",
        "    x = residual_block(x, filters=128, strides=(1,1))\n",
        "    x = residual_block(x, filters=128, strides=(1,1))\n",
        "    \n",
        "    x = residual_block(x, filters=256, strides=(2,2))\n",
        "    x = residual_block(x, filters=256, strides=(1,1))\n",
        "    x = residual_block(x, filters=256, strides=(1,1))\n",
        "    x = residual_block(x, filters=256, strides=(1,1))\n",
        "    x = residual_block(x, filters=256, strides=(1,1))\n",
        "    x = residual_block(x, filters=256, strides=(1,1))\n",
        "    \n",
        "    x = residual_block(x, filters=512, strides=(2,2))\n",
        "    x = residual_block(x, filters=512, strides=(1,1))\n",
        "    x = residual_block(x, filters=512, strides=(1,1))\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(n_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=input, outputs=x)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxUpfhJ1xXle"
      },
      "source": [
        "## 4.모델링 II\n",
        "* **세부요구사항**\n",
        "    - 성능을 높이기 위해서 다음의 두가지를 시도해 봅시다.\n",
        "        - Data Augmentation을 통해 데이터를 증가 시킵니다.\n",
        "            - ImageDataGenerator를 사용합니다.\n",
        "        - 사전 학습된 모델(Transfer Learning)을 가져다 사용해 봅시다.\n",
        "            - VGG16(이미지넷)을 사용해 봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouCRBdKPxCut"
      },
      "source": [
        "### (1) Data Augmentation\n",
        "- **세부요구사항**\n",
        "    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n",
        "    * Keras의 ImageDataGenerator를 이용\n",
        "        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
        "\n",
        "    * image generator를 이용하여 학습\n",
        "        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe6yjs8F7Zox"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYae9YFt8Q03"
      },
      "outputs": [],
      "source": [
        "img_size = 280 ## 사이즈 조정 가능\n",
        "\n",
        "train_path = dataset_path+'Car_Images_train/'\n",
        "valid_path = dataset_path+'Car_Images_valid/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP4jIyTGfXD_"
      },
      "source": [
        "#### 1) ImageGenerator 생성\n",
        "* ImageDataGenerator 함수 사용\n",
        "    * 주요 옵션\n",
        "        * rotation_range: 무작위 회전을 적용할 각도 범위\n",
        "        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n",
        "        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n",
        "        * vertical_flip: 무작위 상하반전을 적용할지 여부\n",
        "        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKPPSwYn7Zrj"
      },
      "outputs": [],
      "source": [
        "train_datagen = \n",
        "\n",
        "valid_datagen = \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKwSYYkufanb"
      },
      "source": [
        "#### 2) 경로로 부터 이미지 불러 올 준비\n",
        "* .flow_from_directory 이용\n",
        "    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n",
        "    * 이미지를 불러올 때 target_size로 크기를 맞추고, \n",
        "    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bwvQ4hHSCwY"
      },
      "outputs": [],
      "source": [
        "train_generator = \n",
        "\n",
        "valid_generator = \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4RPCjU5f662"
      },
      "source": [
        "#### 3) 학습\n",
        "- **세부요구사항**\n",
        "    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n",
        "    - 학습시 train_generator 이용. \n",
        "    - validation_data = valid_generator 지정\n",
        "    - Early Stopping 적용\n",
        "    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVMLsXw6f663"
      },
      "source": [
        "* 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W7rqgH1f663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw2_G7zdf663"
      },
      "source": [
        "* 학습\n",
        "    * EarlyStopping 설정하기\n",
        "    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m5mRE9Nf663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCWzBSYqf663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdKiY1uIf663"
      },
      "source": [
        "#### 4) 성능 평가\n",
        "* 평가는 confusion_matrix, classification_report 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qjnvt0lf663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBl4Do0af663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1iv22vSxXle"
      },
      "source": [
        "### (2) Transfer Learning\n",
        "- **세부요구사항**\n",
        "    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다. \n",
        "        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n",
        "        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n",
        "    * VGG16 함수로 부터 base_model 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnS12YhDxXle"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3kyvCwIiAfi"
      },
      "source": [
        "#### 1) VGG16 불러와서 저장하기\n",
        "* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n",
        "* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFf3IxbBGe9B"
      },
      "outputs": [],
      "source": [
        "base_model = VGG16(                 )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-JjBLZZiIxA"
      },
      "source": [
        "#### 2) VGG16과 연결한 구조 설계\n",
        "* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg4KhHQ8xXlf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V5heiDxxXlf"
      },
      "source": [
        "#### 3) 학습\n",
        "- **세부요구사항**\n",
        "    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n",
        "    - 데이터\n",
        "        * Image Generator를 연결하거나\n",
        "        * 기존 train, validation 셋을 이용해도 됩니다.\n",
        "        - Early Stopping을 반드시 사용하세요.\n",
        "        - 최적의 가중치를 모델에 적용하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtqQIS-HxXlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zg0L88Gwf4l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbhiWcS5i735"
      },
      "source": [
        "#### 4) 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik4AFzCQi735"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkkSsyMoi735"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGuQMUJNxXSy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
