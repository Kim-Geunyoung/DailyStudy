{"cells":[{"cell_type":"markdown","source":["# 딥러닝\n","- framework\n","    - Tensorflow\n","        - keras\n","            - Sequential API\n","                - 선형회귀\n","                - logistic 회귀\n","                - Multi-Class\n","            - Functional API\n","            "],"metadata":{"id":"103432a5-d4d0-442c-b3a8-68f13f69d3eb"},"id":"103432a5-d4d0-442c-b3a8-68f13f69d3eb"},{"cell_type":"markdown","source":["## Multi-Class"],"metadata":{"id":"cd79eb2e-2a75-422b-9423-7877ddb22882"},"id":"cd79eb2e-2a75-422b-9423-7877ddb22882"},{"cell_type":"markdown","source":["Multi-Class는 3개 이상의 output에서 가장 확률이 높은 클래스를 고르는 것이다.\n","Multi-Class 분류에 필요한 기술  \n","    - one-hot encoding  \n","    - softmax function"],"metadata":{"id":"XMfwTEjiPx-a"},"id":"XMfwTEjiPx-a"},{"cell_type":"markdown","source":["## one-hot encoding\n","> target의 형태를 클래스 수만큼 나눈다.\n","- 사용 방법  \n","    > from tensorflow.keras.utils import to_categorical  \n","    > y = to_categorical(y, n)  -> n은 클래스 수"],"metadata":{"id":"8PQChl-lu2uJ"},"id":"8PQChl-lu2uJ"},{"cell_type":"markdown","source":["## softmax function\n","$ y_k = \\frac{exp(a_k)}{\\sum_{i}^{n}(exp(a_i))} $\n","> softmax는 3개 이상으로 분류되는 Multi-Class 분류에서 사용되는 활성화 함수이다.  \n","> softmax는 input 값을 output으로 [0,1]의 범위의 값으로 정규화 하며 모든 output의 합은 1이 되게 해주는 함수이다.  \n","Ex) output이 3개 -> 각각의 값이 0.8, 0.7, 0.4 인 경우 각 확률의 총합이 확률의 범위인 [0,1]을 넘어가기 때문에 softmax를 사용하여 0.7, 0.2, 0.1로 확률의 범위로 변환해주는 기능\n"],"metadata":{"id":"ouQSt326SozC"},"id":"ouQSt326SozC"},{"cell_type":"markdown","source":["## 실습"],"metadata":{"id":"XFN5wc_Iu580"},"id":"XFN5wc_Iu580"},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.datasets import load_iris"],"metadata":{"id":"lMDnY4V1u77-"},"id":"lMDnY4V1u77-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = load_iris()\n","x = data.data\n","y = data.target"],"metadata":{"id":"o5dcgv7Gvgjo"},"id":"o5dcgv7Gvgjo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# one-hot 인코딩\n","from tensorflow.keras.utils import to_categorical\n","y = to_categorical(y, 3)"],"metadata":{"id":"M96Wl3Swvsac"},"id":"M96Wl3Swvsac","execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.shape, y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6mM78qIrv3s9","executionInfo":{"status":"ok","timestamp":1677516375571,"user_tz":-540,"elapsed":6,"user":{"displayName":"김근영","userId":"15518782436185757366"}},"outputId":"2a9d9e6b-4977-4df4-892c-217963a9928c"},"id":"6mM78qIrv3s9","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((150, 4), (150, 3))"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Multi-Class Sequential API\n","# 세션 클리어\n","keras.backend.clear_session()\n","\n","# 모델 선언\n","model = keras.models.Sequential()\n","\n","# 모델 레이어 쌓기\n","model.add(keras.layers.Input(shape=(4, )))\n","model.add(keras.layers.Dense(3, activation='softmax'))"],"metadata":{"id":"VLIXI8v-v6-i"},"id":"VLIXI8v-v6-i","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 컴파일\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"],"metadata":{"id":"o2-bE4f5wkC_"},"id":"o2-bE4f5wkC_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습\n","model.fit(x, y, epochs=100, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zer_kTCBw63B","executionInfo":{"status":"ok","timestamp":1677516381034,"user_tz":-540,"elapsed":3430,"user":{"displayName":"김근영","userId":"15518782436185757366"}},"outputId":"b5244c94-f373-42ce-bd75-bdc0bbe9024d"},"id":"zer_kTCBw63B","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","5/5 [==============================] - 1s 6ms/step - loss: 1.7924 - accuracy: 0.0933\n","Epoch 2/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.7581 - accuracy: 0.0867\n","Epoch 3/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.7248 - accuracy: 0.0800\n","Epoch 4/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.6890 - accuracy: 0.0800\n","Epoch 5/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.6583 - accuracy: 0.0733\n","Epoch 6/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.6253 - accuracy: 0.0733\n","Epoch 7/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.5944 - accuracy: 0.0733\n","Epoch 8/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.5633 - accuracy: 0.0733\n","Epoch 9/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.5334 - accuracy: 0.0733\n","Epoch 10/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.5012 - accuracy: 0.0733\n","Epoch 11/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.4722 - accuracy: 0.0667\n","Epoch 12/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.4404 - accuracy: 0.0733\n","Epoch 13/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.4135 - accuracy: 0.0733\n","Epoch 14/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.3844 - accuracy: 0.0667\n","Epoch 15/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.3562 - accuracy: 0.0667\n","Epoch 16/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.3284 - accuracy: 0.0733\n","Epoch 17/100\n","5/5 [==============================] - 0s 5ms/step - loss: 1.3031 - accuracy: 0.0800\n","Epoch 18/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.2756 - accuracy: 0.0800\n","Epoch 19/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.2492 - accuracy: 0.0800\n","Epoch 20/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.2255 - accuracy: 0.0800\n","Epoch 21/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.2006 - accuracy: 0.0733\n","Epoch 22/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.1786 - accuracy: 0.0667\n","Epoch 23/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.1541 - accuracy: 0.0667\n","Epoch 24/100\n","5/5 [==============================] - 0s 4ms/step - loss: 1.1335 - accuracy: 0.0667\n","Epoch 25/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.1125 - accuracy: 0.0667\n","Epoch 26/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0925 - accuracy: 0.0733\n","Epoch 27/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0729 - accuracy: 0.0733\n","Epoch 28/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0549 - accuracy: 0.0733\n","Epoch 29/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0373 - accuracy: 0.0867\n","Epoch 30/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.0867\n","Epoch 31/100\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.0867\n","Epoch 32/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.9917 - accuracy: 0.0933\n","Epoch 33/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.9777 - accuracy: 0.1000\n","Epoch 34/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.9649 - accuracy: 0.1133\n","Epoch 35/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.9519 - accuracy: 0.1200\n","Epoch 36/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.9417 - accuracy: 0.1333\n","Epoch 37/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.9314 - accuracy: 0.1600\n","Epoch 38/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.9212 - accuracy: 0.1800\n","Epoch 39/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.9129 - accuracy: 0.1933\n","Epoch 40/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.9044 - accuracy: 0.2200\n","Epoch 41/100\n","5/5 [==============================] - 0s 6ms/step - loss: 0.8954 - accuracy: 0.2467\n","Epoch 42/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8883 - accuracy: 0.2800\n","Epoch 43/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8816 - accuracy: 0.2867\n","Epoch 44/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8745 - accuracy: 0.3133\n","Epoch 45/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8684 - accuracy: 0.3267\n","Epoch 46/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8633 - accuracy: 0.3467\n","Epoch 47/100\n","5/5 [==============================] - 0s 5ms/step - loss: 0.8567 - accuracy: 0.3533\n","Epoch 48/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8516 - accuracy: 0.3733\n","Epoch 49/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8460 - accuracy: 0.3867\n","Epoch 50/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.8410 - accuracy: 0.4067\n","Epoch 51/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.8361 - accuracy: 0.4200\n","Epoch 52/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.8314 - accuracy: 0.4333\n","Epoch 53/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.8266 - accuracy: 0.4400\n","Epoch 54/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.8221 - accuracy: 0.4600\n","Epoch 55/100\n","5/5 [==============================] - 0s 5ms/step - loss: 0.8176 - accuracy: 0.4600\n","Epoch 56/100\n","5/5 [==============================] - 0s 5ms/step - loss: 0.8133 - accuracy: 0.4600\n","Epoch 57/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8090 - accuracy: 0.4600\n","Epoch 58/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.8050 - accuracy: 0.4667\n","Epoch 59/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.8006 - accuracy: 0.4733\n","Epoch 60/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7973 - accuracy: 0.4667\n","Epoch 61/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7927 - accuracy: 0.4733\n","Epoch 62/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7886 - accuracy: 0.4733\n","Epoch 63/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7850 - accuracy: 0.4733\n","Epoch 64/100\n","5/5 [==============================] - 0s 5ms/step - loss: 0.7812 - accuracy: 0.4733\n","Epoch 65/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7775 - accuracy: 0.4800\n","Epoch 66/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7737 - accuracy: 0.4733\n","Epoch 67/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.4733\n","Epoch 68/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7666 - accuracy: 0.4733\n","Epoch 69/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.4733\n","Epoch 70/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7595 - accuracy: 0.4800\n","Epoch 71/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7560 - accuracy: 0.4800\n","Epoch 72/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7528 - accuracy: 0.4867\n","Epoch 73/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7493 - accuracy: 0.4867\n","Epoch 74/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.5000\n","Epoch 75/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.5000\n","Epoch 76/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.5000\n","Epoch 77/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.5000\n","Epoch 78/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7333 - accuracy: 0.5000\n","Epoch 79/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7300 - accuracy: 0.5067\n","Epoch 80/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7271 - accuracy: 0.5067\n","Epoch 81/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7240 - accuracy: 0.5067\n","Epoch 82/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7212 - accuracy: 0.5000\n","Epoch 83/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7183 - accuracy: 0.5067\n","Epoch 84/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.5067\n","Epoch 85/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.5067\n","Epoch 86/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7094 - accuracy: 0.5133\n","Epoch 87/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.5133\n","Epoch 88/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.5133\n","Epoch 89/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.5133\n","Epoch 90/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.5133\n","Epoch 91/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5133\n","Epoch 92/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5200\n","Epoch 93/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5267\n","Epoch 94/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5333\n","Epoch 95/100\n","5/5 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5333\n","Epoch 96/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.5333\n","Epoch 97/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.5333\n","Epoch 98/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.5333\n","Epoch 99/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.5400\n","Epoch 100/100\n","5/5 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.5467\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f13e5e63760>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# 모델 성능 비교\n","print('정답')\n","print(y[:10])\n","print('='*80)\n","print('모델이 예측한 값')\n","print(model.predict(x)[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNYxnRn-xBPL","executionInfo":{"status":"ok","timestamp":1677516431802,"user_tz":-540,"elapsed":442,"user":{"displayName":"김근영","userId":"15518782436185757366"}},"outputId":"ab32d227-c1ed-49ea-ec86-62eb6289b932"},"id":"eNYxnRn-xBPL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["정답\n","[[1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]]\n","================================================================================\n","모델이 예측한 값\n","5/5 [==============================] - 0s 3ms/step\n","[[0.77422845 0.02628164 0.19949001]\n"," [0.6587341  0.05299972 0.28826624]\n"," [0.750597   0.03448304 0.21491991]\n"," [0.71292424 0.04877003 0.2383057 ]\n"," [0.80633193 0.02199154 0.17167647]\n"," [0.80229837 0.01942403 0.17827775]\n"," [0.79535526 0.02672158 0.17792316]\n"," [0.7502094  0.03354248 0.21624796]\n"," [0.6895237  0.05663347 0.2538427 ]\n"," [0.6819483  0.05313057 0.2649211 ]]\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}